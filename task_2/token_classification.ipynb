{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nie uzna gola. Robben był kilka metrów w polu ...</td>\n",
       "      <td>[[0, 8, odwrócenie]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER No właśnie o tym jest ten tweet 😄</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER @USER Widać chcą wiecej polskich mord go...</td>\n",
       "      <td>[[23, 38, wzmocnienie]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Idę spać bo padam na twarz, w końcu w domuuuu</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER Tak się poznałam z moim chłopakiem 😂 cza...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>@USER Wszystkiego najlepszego z okazji urodzin...</td>\n",
       "      <td>[[5, 29, wzmocnienie]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>@USER widzę, że pewne tweety działają jak magn...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>@USER @USER Chociaż futro ma z jenota,\\nTo nie...</td>\n",
       "      <td>[[43, 52, odwrócenie], [55, 67, wzmocnienie], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>@USER Ty aby nie zacząleś ćpać przez wydumane ...</td>\n",
       "      <td>[[13, 25, odwrócenie], [37, 54, wzmocnienie]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>@USER och, to też mój superman w kuchni. Jak c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Nie uzna gola. Robben był kilka metrów w polu ...   \n",
       "1              @USER No właśnie o tym jest ten tweet 😄   \n",
       "2    @USER @USER Widać chcą wiecej polskich mord go...   \n",
       "3        Idę spać bo padam na twarz, w końcu w domuuuu   \n",
       "4    @USER Tak się poznałam z moim chłopakiem 😂 cza...   \n",
       "..                                                 ...   \n",
       "795  @USER Wszystkiego najlepszego z okazji urodzin...   \n",
       "796  @USER widzę, że pewne tweety działają jak magn...   \n",
       "797  @USER @USER Chociaż futro ma z jenota,\\nTo nie...   \n",
       "798  @USER Ty aby nie zacząleś ćpać przez wydumane ...   \n",
       "799  @USER och, to też mój superman w kuchni. Jak c...   \n",
       "\n",
       "                                                 label  \n",
       "0                                 [[0, 8, odwrócenie]]  \n",
       "1                                                   []  \n",
       "2                              [[23, 38, wzmocnienie]]  \n",
       "3                                                   []  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "795                             [[5, 29, wzmocnienie]]  \n",
       "796                                                 []  \n",
       "797  [[43, 52, odwrócenie], [55, 67, wzmocnienie], ...  \n",
       "798      [[13, 25, odwrócenie], [37, 54, wzmocnienie]]  \n",
       "799                                                 []  \n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"../task_1/data/fragments_classification.jsonl\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotated_fragments(labels: list):\n",
    "    frag_dict = {}\n",
    "    for label in labels:\n",
    "        frag_dict[(label[0], label[1])] = label[2]\n",
    "    return frag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(13, 25): 'odwrócenie', (37, 54): 'wzmocnienie'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = get_annotated_fragments(df['label'][798])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odwrócenie\n",
      "odwrócenie\n",
      "odwrócenie\n",
      "odwrócenie\n",
      "odwrócenie\n",
      "Tokens in annotated fragments: [9152, 2063, 1057, 2480, 2532]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(df['text'][0], return_offsets_mapping=True)\n",
    "annotated_fragments = get_annotated_fragments(df['label'][0])\n",
    "# Check tokens against annotated fragments\n",
    "tokens_in_annotations = []\n",
    "for idx, (start, end) in enumerate(encoding['offset_mapping']):\n",
    "    token_text = encoding['input_ids'][idx]\n",
    "    for fragment_start, fragment_end in annotated_fragments:\n",
    "        # Check if token overlaps with the fragment\n",
    "        if start < fragment_end and end > fragment_start:\n",
    "            tokens_in_annotations.append(token_text)  # decode token id to string\n",
    "            print(annotated_fragments[(fragment_start, fragment_end)])\n",
    "\n",
    "print(\"Tokens in annotated fragments:\", tokens_in_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 9152, 2063, 1057, 2480, 2532, 2175, 2721, 1012, 26211, 2368, 2011, 18818, 11382, 26518, 6005, 2860, 1059, 14955, 2226, 10556, 6826, 24335, 1010, 1059, 22571, 22648, 21293, 18818, 17540, 2666, 4241, 4143, 10975, 4371, 4213, 3351, 2079, 2079, 16313, 3211, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 2), (2, 3), (4, 5), (5, 6), (6, 8), (9, 11), (11, 13), (13, 14), (15, 19), (19, 21), (22, 24), (24, 25), (26, 28), (28, 31), (32, 37), (37, 38), (39, 40), (41, 44), (44, 45), (46, 48), (48, 50), (50, 52), (52, 53), (54, 55), (55, 57), (57, 60), (60, 63), (63, 64), (65, 68), (68, 70), (71, 73), (73, 75), (76, 78), (78, 80), (80, 82), (82, 84), (85, 87), (88, 90), (90, 93), (93, 95), (95, 96), (0, 0)]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in annotated fragments: [(9152, 'odwrócenie'), (2063, 'odwrócenie'), (29250, 'odwrócenie'), (16739, 'odwrócenie'), (2229, 'odwrócenie'), (1059, 'wzmocnienie'), (25688, 'wzmocnienie'), (19042, 'wzmocnienie'), (2063, 'wzmocnienie'), (3291, 'wzmocnienie'), (2100, 'wzmocnienie')]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(df['text'][798], return_offsets_mapping=True)\n",
    "annotated_fragments = get_annotated_fragments(df['label'][798])\n",
    "# Check tokens against annotated fragments\n",
    "tokens_in_annotations = []\n",
    "for idx, (start, end) in enumerate(encoding['offset_mapping']):\n",
    "    token_text = encoding['input_ids'][idx]\n",
    "    for fragment_start, fragment_end in annotated_fragments:\n",
    "        # Check if token overlaps with the fragment\n",
    "        if start < fragment_end and end > fragment_start:\n",
    "            tokens_in_annotations.append((token_text, annotated_fragments[(fragment_start, fragment_end)]))\n",
    "\n",
    "print(\"Tokens in annotated fragments:\", tokens_in_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    encoding = tokenizer(row['text'], return_offsets_mapping=True)\n",
    "    annotated_fragments = get_annotated_fragments(row['label'])\n",
    "    # Check tokens against annotated fragments\n",
    "    tokens_in_annotations = []\n",
    "    for idx, (start, end) in enumerate(encoding['offset_mapping']):\n",
    "        token_text = encoding['input_ids'][idx]\n",
    "        for fragment_start, fragment_end in annotated_fragments:\n",
    "            # Check if token overlaps with the fragment\n",
    "            if start < fragment_end and end > fragment_start:\n",
    "                tokens_in_annotations.append((token_text, annotated_fragments[(fragment_start, fragment_end)]))\n",
    "    return tokens_in_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_in_annotations_with_labels'] = df.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9152, 'odwrócenie'),\n",
       " (2063, 'odwrócenie'),\n",
       " (29250, 'odwrócenie'),\n",
       " (16739, 'odwrócenie'),\n",
       " (2229, 'odwrócenie'),\n",
       " (1059, 'wzmocnienie'),\n",
       " (25688, 'wzmocnienie'),\n",
       " (19042, 'wzmocnienie'),\n",
       " (2063, 'wzmocnienie'),\n",
       " (3291, 'wzmocnienie'),\n",
       " (2100, 'wzmocnienie')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens_in_annotations_with_labels'][798]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
