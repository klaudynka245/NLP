{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import stopwordsiso as stopwords\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '..//task_1//data//text_all.jsonl'  \n",
    "data = pd.read_json(file_path, lines=True)\n",
    "\n",
    "\n",
    "labels_map = {\n",
    "    0: \"pozytywny wyd≈∫wiƒôk\",\n",
    "    1: \"neutralny wyd≈∫wiƒôk\",\n",
    "    2: \"negatywny wyd≈∫wiƒôk\",\n",
    "    3: \"mowa nienawi≈õci\",\n",
    "    '0': \"pozytywny wyd≈∫wiƒôk\",\n",
    "    '1': \"neutralny wyd≈∫wiƒôk\",\n",
    "    '2': \"negatywny wyd≈∫wiƒôk\",\n",
    "    '3': \"mowa nienawi≈õci\"\n",
    "}\n",
    "\n",
    "data[\"label\"] = data[\"label\"].replace(labels_map)\n",
    "data['label'] = data['label'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else x)\n",
    "\n",
    "data['label'] = data['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "\n",
    "polish_stopwords = stopwords.stopwords(\"pl\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.strip()\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    lemmatized_words = [token.lemma_ for token in doc if token.lemma_.lower() not in polish_stopwords]\n",
    "\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "data['cleaned_text'] = data['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER Nic, nic,nic niewa≈ºne, jutro albo w najb...</td>\n",
       "      <td>neutralny wyd≈∫wiƒôk</td>\n",
       "      <td>nicnica niewa≈ºny jutro bliski czas odezwƒô narka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER Kibic @USER odpowiada @USER i @USER na k...</td>\n",
       "      <td>neutralny wyd≈∫wiƒôk</td>\n",
       "      <td>kibic   odpowiadaƒá     krytyka Manuel Junconnh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M√≥wi ≈ºe stare rapsy sƒÖ ca≈Çkiem niezle</td>\n",
       "      <td>neutralny wyd≈∫wiƒôk</td>\n",
       "      <td>m√≥wiƒá stary rapsy ca≈Çkiem niezle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER Zaleg≈Ço≈õci by≈Çy, ale wa≈ºne czy by≈Ç...</td>\n",
       "      <td>neutralny wyd≈∫wiƒôk</td>\n",
       "      <td>Zaleg≈Ço≈õƒá wa≈ºny wezwaƒá zap≈Çata klub wywiƒÖzaƒá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Oby nie spierdolil na p√≥≈Çnoc</td>\n",
       "      <td>negatywny wyd≈∫wiƒôk</td>\n",
       "      <td>Oby spierdolil p√≥≈Çnoc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>@USER Noc? To wtedy, gdy jest ciemno? Bo ≈ºadne...</td>\n",
       "      <td>neutralny wyd≈∫wiƒôk</td>\n",
       "      <td>noc ciemno r√≥≈ºnica por√≥wnanie dzie≈Ñ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>wszƒôdzie dobrze, ale w grobie najlepiej</td>\n",
       "      <td>mowa nienawi≈õci</td>\n",
       "      <td>wszƒôdzie groba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>@USER a ile zagra≈Ç tam minut ?</td>\n",
       "      <td>neutralny wyd≈∫wiƒôk</td>\n",
       "      <td>zagraƒá minuta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>@USER #FinalSix: Mamy to !!! Puchar Polski jes...</td>\n",
       "      <td>pozytywny wyd≈∫wiƒôk</td>\n",
       "      <td>FinalSix mieƒá   puchar Polska   Wis≈Ça CanPack ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>@USER @USER a to ju≈º nie moja wina ≈ºe sprzedal...</td>\n",
       "      <td>neutralny wyd≈∫wiƒôk</td>\n",
       "      <td>wino sprzedaƒá byƒá nazwe klub</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4441 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text               label  \\\n",
       "0     @USER Nic, nic,nic niewa≈ºne, jutro albo w najb...  neutralny wyd≈∫wiƒôk   \n",
       "1     @USER Kibic @USER odpowiada @USER i @USER na k...  neutralny wyd≈∫wiƒôk   \n",
       "2                 M√≥wi ≈ºe stare rapsy sƒÖ ca≈Çkiem niezle  neutralny wyd≈∫wiƒôk   \n",
       "3     @USER @USER Zaleg≈Ço≈õci by≈Çy, ale wa≈ºne czy by≈Ç...  neutralny wyd≈∫wiƒôk   \n",
       "4              @USER @USER Oby nie spierdolil na p√≥≈Çnoc  negatywny wyd≈∫wiƒôk   \n",
       "...                                                 ...                 ...   \n",
       "4436  @USER Noc? To wtedy, gdy jest ciemno? Bo ≈ºadne...  neutralny wyd≈∫wiƒôk   \n",
       "4437            wszƒôdzie dobrze, ale w grobie najlepiej     mowa nienawi≈õci   \n",
       "4438                     @USER a ile zagra≈Ç tam minut ?  neutralny wyd≈∫wiƒôk   \n",
       "4439  @USER #FinalSix: Mamy to !!! Puchar Polski jes...  pozytywny wyd≈∫wiƒôk   \n",
       "4440  @USER @USER a to ju≈º nie moja wina ≈ºe sprzedal...  neutralny wyd≈∫wiƒôk   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0       nicnica niewa≈ºny jutro bliski czas odezwƒô narka  \n",
       "1     kibic   odpowiadaƒá     krytyka Manuel Junconnh...  \n",
       "2                      m√≥wiƒá stary rapsy ca≈Çkiem niezle  \n",
       "3          Zaleg≈Ço≈õƒá wa≈ºny wezwaƒá zap≈Çata klub wywiƒÖzaƒá  \n",
       "4                                 Oby spierdolil p√≥≈Çnoc  \n",
       "...                                                 ...  \n",
       "4436                noc ciemno r√≥≈ºnica por√≥wnanie dzie≈Ñ  \n",
       "4437                                     wszƒôdzie groba  \n",
       "4438                                      zagraƒá minuta  \n",
       "4439  FinalSix mieƒá   puchar Polska   Wis≈Ça CanPack ...  \n",
       "4440                       wino sprzedaƒá byƒá nazwe klub  \n",
       "\n",
       "[4441 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\kjani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "  0%|          | 0/168 [25:59<?, ?it/s]\n",
      "  0%|          | 2/2667 [00:00<07:58,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4287, 'grad_norm': 6.49643087387085, 'learning_rate': 4.998125234345707e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 502/2667 [00:37<02:42, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2961, 'grad_norm': 4.030407905578613, 'learning_rate': 4.0626171728533934e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 888/2667 [01:06<02:14, 13.24it/s]c:\\Users\\kjani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 890/2667 [01:09<18:58,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.296167016029358, 'eval_accuracy': 0.449634214969049, 'eval_f1': 0.2789268150312656, 'eval_precision': 0.20217092727083294, 'eval_recall': 0.449634214969049, 'eval_runtime': 3.7844, 'eval_samples_per_second': 469.559, 'eval_steps_per_second': 58.926, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 1002/2667 [01:18<02:11, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2994, 'grad_norm': 4.1368231773376465, 'learning_rate': 3.1252343457067865e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1502/2667 [01:56<01:30, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2934, 'grad_norm': 3.506744861602783, 'learning_rate': 2.18785151856018e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1778/2667 [02:17<01:18, 11.30it/s]c:\\Users\\kjani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1780/2667 [02:21<10:11,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.287301778793335, 'eval_accuracy': 0.449634214969049, 'eval_f1': 0.2789268150312656, 'eval_precision': 0.20217092727083294, 'eval_recall': 0.449634214969049, 'eval_runtime': 4.034, 'eval_samples_per_second': 440.501, 'eval_steps_per_second': 55.279, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2002/2667 [02:39<00:52, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2783, 'grad_norm': 4.280080318450928, 'learning_rate': 1.2504686914135733e-05, 'epoch': 2.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2502/2667 [03:18<00:12, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2916, 'grad_norm': 5.238785743713379, 'learning_rate': 3.1308586426696664e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2666/2667 [03:30<00:00, 13.00it/s]c:\\Users\\kjani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2667/2667 [03:36<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2880703210830688, 'eval_accuracy': 0.449634214969049, 'eval_f1': 0.2789268150312656, 'eval_precision': 0.20217092727083294, 'eval_recall': 0.449634214969049, 'eval_runtime': 4.1117, 'eval_samples_per_second': 432.183, 'eval_steps_per_second': 54.236, 'epoch': 3.0}\n",
      "{'train_runtime': 216.9358, 'train_samples_per_second': 98.255, 'train_steps_per_second': 12.294, 'train_loss': 1.2899724801560222, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 219/223 [00:04<00:00, 53.38it/s]c:\\Users\\kjani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 223/223 [00:04<00:00, 51.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2880703210830688,\n",
       " 'eval_accuracy': 0.449634214969049,\n",
       " 'eval_f1': 0.2789268150312656,\n",
       " 'eval_precision': 0.20217092727083294,\n",
       " 'eval_recall': 0.449634214969049,\n",
       " 'eval_runtime': 4.3228,\n",
       " 'eval_samples_per_second': 411.081,\n",
       " 'eval_steps_per_second': 51.588,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['cleaned_text'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "\n",
    "label_to_id = {label: idx for idx, label in enumerate(set(labels))}\n",
    "num_labels = len(label_to_id)\n",
    "numeric_labels = [label_to_id[label] for label in labels]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "def mask_tokens(inputs, mask_prob=0.15):\n",
    "    outputs = []\n",
    "    for input_ids in inputs:\n",
    "        output_ids = input_ids.clone()\n",
    "        num_to_mask = int(len(input_ids) * mask_prob)  \n",
    "        mask_indices = random.sample(range(len(input_ids)), num_to_mask) \n",
    "\n",
    "        for idx in mask_indices:\n",
    "            output_ids[idx] = tokenizer.mask_token_id  \n",
    "        \n",
    "        outputs.append(output_ids.unsqueeze(0))  \n",
    "    return torch.cat(outputs)  \n",
    "\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "\n",
    "augmented_inputs = mask_tokens(inputs['input_ids'])\n",
    "augmented_labels = numeric_labels * (augmented_inputs.size(0) // inputs['input_ids'].size(0))  # Powiel etykiety\n",
    "\n",
    "combined_inputs = torch.cat((inputs['input_ids'], augmented_inputs), dim=0)\n",
    "combined_labels = numeric_labels + augmented_labels\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(combined_inputs, combined_labels, test_size=0.2)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_ids, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long) \n",
    "        }\n",
    "\n",
    "train_dataset = CustomDataset(train_inputs, train_labels)\n",
    "val_dataset = CustomDataset(val_inputs, val_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    logging_dir='./logs',         \n",
    "    logging_steps=500,\n",
    "    logging_first_step=True,  \n",
    "    report_to='tensorboard'  \n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
