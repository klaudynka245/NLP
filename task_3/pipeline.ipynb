{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Literal\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from transformers import BertTokenizer\n",
    "import faiss\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'sentence-transformers/squad'\n",
    "RETRIEVER_NAME = 'multi-qa-mpnet-base-dot-v1'\n",
    "RERANKER_NAME = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "questions = dataset['train']['question']\n",
    "answers = list(set(dataset['train']['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SentenceTransformer(RETRIEVER_NAME).to(DEVICE)\n",
    "reranker = CrossEncoder(RERANKER_NAME, max_length = 512, device = DEVICE)\n",
    "tokenizer = BertTokenizer.from_pretrained(RERANKER_NAME, max_length = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_vec = retriever.encode(questions)\n",
    "answers_vec = retriever.encode(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = faiss.IndexFlatIP(answers_vec.shape[1])\n",
    "faiss_index.add(np.array(answers_vec, dtype = np.float32))\n",
    "faiss_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, faiss_index)\n",
    "\n",
    "def retrive(query: str, top_k: int, answers: list[str] = answers, answers_vec: np.array = answers_vec) -> list[dict]:\n",
    "    retrive_list = list()\n",
    "    pos = list()\n",
    "    \n",
    "    query_vec = retriever.encode([query])[0]\n",
    "    distances, indices = faiss_index.search(np.array([query_vec], dtype=np.float32), top_k)\n",
    "    \n",
    "    for i, index in enumerate(indices[0]):\n",
    "        retrive_dict = dict()\n",
    "        \n",
    "        distance = distances[0][i]\n",
    "        retrive_dict['rank'] = i + 1\n",
    "        retrive_dict['text'] = answers[index]\n",
    "        retrive_dict['distance'] = distance\n",
    "        retrive_dict['vector'] = answers_vec[index]\n",
    "        retrive_list.append(retrive_dict)\n",
    "        \n",
    "    return retrive_list\n",
    "\n",
    "\n",
    "\n",
    "def rerank(query: str, retrive_list: list[dict], top_k: int) -> list[dict]:\n",
    "    retrive_answers = [dct['text'] for dct in retrive_list]\n",
    "    reranking = reranker.rank(query, retrive_answers, top_k = top_k, return_documents = True)\n",
    "    \n",
    "    return reranking\n",
    "\n",
    "        \n",
    "        \n",
    "def print_results(query, rerank_answers):\n",
    "    print(f'Query: {query}\\n')\n",
    "    print(f\"Real answer: {dataset['train']['answer'][questions.index(query)]}\\n\\n\")\n",
    "    print(f'Top {len(rerank_answers)} answers:\\n')\n",
    "    for i in range(len(rerank_answers)):\n",
    "        print(f\"Answer {i + 1}: {rerank_answers[i]['text']}, {rerank_answers[i]['score']}\\n\")            \n",
    "\n",
    "\n",
    "\n",
    "def get_answer_rating(query, retrive_answers, rerank_answers):\n",
    "    correct_answer = dataset['train']['answer'][questions.index(query)]\n",
    "    \n",
    "    retriver_idx = len(retrive_answers)\n",
    "    for i, answer in enumerate([dct['text'] for dct in retrive_answers]):\n",
    "        if correct_answer == answer:\n",
    "            retriver_idx = i\n",
    "            break\n",
    "    \n",
    "    rerank_idx = len(rerank_answers)\n",
    "    for i, answer in enumerate([dct['text'] for dct in rerank_answers]):\n",
    "        if correct_answer == answer:\n",
    "            rerank_idx = i\n",
    "            break\n",
    "    \n",
    "    return retriver_idx, rerank_idx\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics_base(queries, top_k_retriver, top_k_reranker):\n",
    "    retriver_idxs, rerank_idxs = list(), list()\n",
    "    \n",
    "    for query in queries:\n",
    "        retrive_list = retrive(query, top_k = top_k_retriver)\n",
    "        rerank_list = rerank(query, retrive_list, top_k = top_k_reranker)\n",
    "        \n",
    "        retriver_idx, rerank_idx = get_answer_rating(query, retrive_list, rerank_list)\n",
    "        retriver_idxs.append(retriver_idx)\n",
    "        rerank_idxs.append(rerank_idx)\n",
    "    \n",
    "    return retriver_idxs, rerank_idxs\n",
    "\n",
    "\n",
    "recall_k = lambda idxs, k: sum(1 for x in idxs if x <= k) / len(idxs) \n",
    "mrr = lambda idxs: np.mean([1 / (idx + 1) for idx in idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrive_idxs, rerank_idxs = get_metrics_base(questions[:10000], 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriver:\t\trecall@1 = 0.66\t\trecall@10 = 0.94\t\trecall@50 = 0.98\n",
      "Reranker:\t\trecall@1 = 0.81\t\trecall@10 = 0.96\t\trecall@50 = 0.98\n"
     ]
    }
   ],
   "source": [
    "print(f'Retriver:\\t\\trecall@1 = {recall_k(retrive_idxs, 0):.2f}\\t\\trecall@10 = {recall_k(retrive_idxs, 9):.2f}\\t\\trecall@50 = {recall_k(retrive_idxs, 49):.2f}')\n",
    "print(f'Reranker:\\t\\trecall@1 = {recall_k(rerank_idxs, 0):.2f}\\t\\trecall@10 = {recall_k(rerank_idxs, 9):.2f}\\t\\trecall@50 = {recall_k(rerank_idxs, 49):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank\n",
      "Retriver: 0.77\n",
      "Reranker: 0.87\n"
     ]
    }
   ],
   "source": [
    "print('Mean Reciprocal Rank')\n",
    "print(f'Retriver: {mrr(retrive_idxs):.2f}')\n",
    "print(f'Reranker: {mrr(rerank_idxs):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
