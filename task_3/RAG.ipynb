{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.read_index(\"index/wikipedia_202307.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x0000026448181020> >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'id': 'bielik', 'full_name': 'speakleash/Bielik-11B-v2.2-Instruct', 'name': 'speakleash/Bielik-11B-v2.2-Instruct'}, {'id': 'cohere', 'full_name': 'CohereForAI/c4ai-command-r-plus', 'name': 'CohereForAI/c4ai-command-r-plus'}, {'id': 'mixtral-8x22B', 'full_name': 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'name': 'mistralai/Mixtral-8x22B-Instruct-v0.1'}, {'id': 'llama3.1-8b', 'full_name': 'meta-llama/Llama-3.1-8B-Instruct', 'name': 'meta-llama/Llama-3.1-8B-Instruct'}, {'id': 'llama', 'full_name': 'meta-llama/Llama-3.1-8B-Instruct', 'name': 'meta-llama/Llama-3.1-8B-Instruct'}, {'id': 'llama-guard', 'full_name': 'meta-llama/Llama-Guard-3-8B', 'name': 'meta-llama/Llama-Guard-3-8B'}, {'id': 'llama3.1', 'full_name': 'meta-llama/Meta-Llama-3.1-70B-Instruct', 'name': 'meta-llama/Meta-Llama-3.1-70B-Instruct'}, {'id': 'openchat', 'full_name': 'openchat/openchat-3.5-1210', 'name': 'openchat/openchat-3.5-1210'}, {'id': 'pllum-shparag-llama3-8B', 'full_name': 'pllum/rag_70k_nemotron_finetune_pol_llama8b', 'name': 'pllum/rag_70k_nemotron_finetune_pol_llama8b'}, {'id': 'pllum-rag-shparag', 'full_name': 'pllum/mixtral_8x7B_pl_max1k_with_2335_dialog_and_external_data_v3_max_1k_mvpv2_v0.1', 'name': 'pllum/mixtral_8x7B_pl_max1k_with_2335_dialog_and_external_data_v3_max_1k_mvpv2_v0.1'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"CLARIN_API_KEY\")\n",
    "\n",
    "MODELS_ENDPOINT = \"https://services.clarin-pl.eu/api/v1/oapi/models\"\n",
    "COMPLETIONS_ENDPOINT = \"https://services.clarin-pl.eu/api/v1/oapi/chat/completions\"\n",
    "\n",
    "def get_models():\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',  \n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.get(MODELS_ENDPOINT, headers=headers)  \n",
    "    if response.status_code == 200:\n",
    "        return response.json()  \n",
    "\n",
    "models = get_models()\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_from_faiss(query, faiss_results):\n",
    "    # 1. Przygotuj kontekst na podstawie wyników FAISS\n",
    "    context = \"\\n\".join([str(result) for result in faiss_results])  # Zmienna `result` to fragmenty tekstów z FAISS\n",
    "    \n",
    "    # 2. Przygotuj zapytanie do modelu\n",
    "    prompt = f\"Given the following context, answer the question: {query}\\n\\nContext:\\n{context}\"\n",
    "    \n",
    "    # 3. Nagłówki do zapytania\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',  # Twój klucz API CLARIN\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    # 4. Przygotowanie danych do wysłania\n",
    "    data = {\n",
    "        \"model\": \"meta-llama/Llama-3.1-8B-Instruct\",  # Wybrany model\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(COMPLETIONS_ENDPOINT, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        return response_data['choices'][0]['message']['content']\n",
    "    else:\n",
    "        print(f\"Failed to generate response: {response.status_code}, {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from faiss import read_index\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS as LangChainFAISS\n",
    "\n",
    "# Załaduj indeks FAISS\n",
    "index_path = \"index/wikipedia_202307.index\"\n",
    "sentence_index = read_index(index_path)\n",
    "\n",
    "# Ustawienia API CLARIN\n",
    "api_key = API_KEY\n",
    "base_url = \"https://services.clarin-pl.eu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from CLARIN API: {'detail': \"Non existing model 'meta-llama/Llama-3.1-8B-Instruct'\"}\n",
      "Error: The response from the API does not contain 'choices'.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"CLARIN_API_KEY\")\n",
    "\n",
    "# Ścieżka do pliku z indeksem FAISS\n",
    "index_path = \"index/wikipedia_202307.index\"\n",
    "\n",
    "# Inicjalizacja modelu do zamiany tekstu na wektory\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Ładowanie indeksu FAISS\n",
    "def load_faiss_index(index_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    return index\n",
    "\n",
    "# Funkcja do pobierania tytułów artykułów z indeksu FAISS\n",
    "def get_titles_from_faiss_index(index, k=5):\n",
    "    # Pobierz tytuły artykułów zapisane w FAISS w formie stringów (zakładając, że tytuły są zapisane w docstrings)\n",
    "    # Pierwszym krokiem jest przekonwertowanie numerów indeksów na teksty\n",
    "    titles = []\n",
    "    for i in range(k):  # Załóżmy, że przeszukamy 5 wyników\n",
    "        # Wczytaj tytuły z wyników\n",
    "        title = f\"Article {i}\"  # W miejsce 'Article {i}' powinny pojawić się odpowiednie tytuły zapisane w FAISS\n",
    "        titles.append(title)\n",
    "    return titles\n",
    "\n",
    "# Konwersja tekstu na wektor\n",
    "def text_to_vector(text):\n",
    "    return model.encode([text])[0]\n",
    "\n",
    "# Wyszukiwanie podobnych dokumentów w indeksie FAISS\n",
    "def retrieve_similar_documents(query, index, k=5):\n",
    "    query_vector = text_to_vector(query)  # Przekształć zapytanie na wektor\n",
    "    query_vector = np.array([query_vector]).astype(np.float32)  # Faiss wymaga typu np.float32\n",
    "    distances, indices = index.search(query_vector, k)  # k to liczba najbliższych sąsiadów\n",
    "    return indices, distances\n",
    "\n",
    "# Funkcja do pobierania pełnych artykułów z Wikipedii na podstawie tytułów\n",
    "def get_wikipedia_article(title):\n",
    "    url = f\"https://pl.wikipedia.org/w/api.php?action=query&format=json&prop=extracts&exintro&titles={title}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "        page_id = list(pages.keys())[0]\n",
    "        extract = pages[page_id].get(\"extract\", \"No extract available.\")\n",
    "        return extract\n",
    "    else:\n",
    "        return \"Error fetching article.\"\n",
    "\n",
    "# Funkcja do generowania odpowiedzi z API CLARIN\n",
    "def generate_answer_from_clarin(query, context):\n",
    "    url = \"https://services.clarin-pl.eu/api/v1/oapi/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"pllum/rag_70k_nemotron_finetune_pol_llama8b\",  # Użycie wybranego modelu\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            {\"role\": \"assistant\", \"content\": context}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        return response_data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"No answer found\")\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\"\n",
    "\n",
    "# Funkcja do pobrania dokumentów z Wikipedii na podstawie wyników FAISS\n",
    "def get_documents_from_indices(indices, index, k=5):\n",
    "    titles = get_titles_from_faiss_index(index, k)  # Pobieramy tytuły z indeksu\n",
    "    documents = []\n",
    "    for idx in indices[0]:  # Zakładamy, że wektory są jednowymiarowe (rozmiar k, 1)\n",
    "        title = titles[idx]  # Mapowanie indeksu na tytuł (prosty sposób)\n",
    "        article = get_wikipedia_article(title)\n",
    "        documents.append(f\"Title: {title}\\n{article}\\n\")\n",
    "    \n",
    "    return \"\\n\".join(documents)\n",
    "\n",
    "# Główna funkcja do obsługi procesu RAG\n",
    "def rag_system(query):\n",
    "    # Załaduj indeks FAISS\n",
    "    index = load_faiss_index(index_path)\n",
    "    \n",
    "    # Wyszukaj najbardziej podobne dokumenty w FAISS\n",
    "    indices, distances = retrieve_similar_documents(query, index)\n",
    "\n",
    "    # Pobierz dokumenty z Wikipedii na podstawie wyników\n",
    "    context = get_documents_from_indices(indices, index)\n",
    "\n",
    "    # Wygeneruj odpowiedź z CLARIN na podstawie kontekstu\n",
    "    answer = generate_answer_from_clarin(query, context)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Przykład użycia systemu RAG\n",
    "query = \"Co to jest sztuczna inteligencja?\"\n",
    "answer = rag_system(query)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate response: 404, {\"detail\":\"Non existing model 'speakleash/Bielik-11B-v2.2-Instruct'\"}\n",
      "Response from model: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from faiss import read_index\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Załaduj zmienne środowiskowe z pliku .env\n",
    "load_dotenv()\n",
    "\n",
    "# Odczytaj klucz API CLARIN z pliku .env\n",
    "API_KEY = os.getenv(\"CLARIN_API_KEY\")\n",
    "\n",
    "# Endpointy API CLARIN\n",
    "MODELS_ENDPOINT = \"https://services.clarin-pl.eu/api/v1/oapi/models\"\n",
    "COMPLETIONS_ENDPOINT = \"https://services.clarin-pl.eu/api/v1/oapi/chat/completions\"\n",
    "\n",
    "# Endpoint API Wikipedii\n",
    "WIKIPEDIA_API_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# Ścieżka do indeksu FAISS\n",
    "index_path = \"index/wikipedia_202307.index\"  # Zaktualizuj ścieżkę do pliku .index\n",
    "\n",
    "# Załaduj model SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Załaduj indeks FAISS\n",
    "index = read_index(index_path)\n",
    "\n",
    "# Funkcja do generowania embeddingu zapytania\n",
    "def get_embedding(query):\n",
    "    # Generowanie embeddingu dla zapytania\n",
    "    embedding = model.encode(query)\n",
    "    return np.array([embedding]).astype(np.float32)  # Konwersja na odpowiedni format FAISS\n",
    "\n",
    "# Funkcja do wyszukiwania podobnych artykułów w FAISS\n",
    "def search_faiss(query_embedding, k=5):\n",
    "    _, indices = index.search(query_embedding, k)  # k to liczba wyników\n",
    "    return indices\n",
    "\n",
    "# Funkcja do pobierania pełnych artykułów z Wikipedii\n",
    "def get_wikipedia_article(title):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"exintro\": True,  # Pobieramy tylko wstęp artykułu\n",
    "        \"explaintext\": True\n",
    "    }\n",
    "    response = requests.get(WIKIPEDIA_API_ENDPOINT, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Zwróć pełny artykuł, jeśli został znaleziony\n",
    "    pages = data[\"query\"][\"pages\"]\n",
    "    page_id = next(iter(pages))  # Pobierz pierwszy (jedyny) artykuł\n",
    "    article_text = pages[page_id].get(\"extract\", \"No content found\")\n",
    "    \n",
    "    return article_text\n",
    "\n",
    "# Funkcja do generowania odpowiedzi na podstawie wyników FAISS i modelu CLARIN\n",
    "def generate_response_from_faiss(query, faiss_results):\n",
    "    # Przygotuj kontekst na podstawie wyników FAISS\n",
    "    context = \"\\n\".join([str(result) for result in faiss_results])  # Zmienna `result` to fragmenty tekstów z FAISS\n",
    "    \n",
    "    # Przygotuj zapytanie do modelu\n",
    "    prompt = f\"Given the following context, answer the question: {query}\\n\\nContext:\\n{context}\"\n",
    "    \n",
    "    # Nagłówki do zapytania\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',  # Twój klucz API CLARIN\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    # Przygotowanie danych do wysłania\n",
    "    data = {\n",
    "        \"model\": 'speakleash/Bielik-11B-v2.2-Instruct',  # Wybrany model\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    \n",
    "    # Wysyłanie zapytania do modelu\n",
    "    response = requests.post(COMPLETIONS_ENDPOINT, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        return response_data['choices'][0]['message']['content']\n",
    "    else:\n",
    "        print(f\"Failed to generate response: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Funkcja do integracji RAG (Retrieval-Augmented Generation) za pomocą LangChain\n",
    "def run_rag_chain(query):\n",
    "    # Generowanie embeddingu zapytania\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    # Wyszukiwanie podobnych artykułów w FAISS\n",
    "    indices = search_faiss(query_embedding)\n",
    "    \n",
    "    # Zakładając, że 'indices' zawierają numery indeksów w FAISS, które reprezentują tytuły artykułów\n",
    "    # Przykładowe tytuły artykułów (należy zamienić je na rzeczywiste tytuły na podstawie wyników FAISS)\n",
    "    faiss_titles = []  # Lista tytułów, które odpowiadają indeksom FAISS\n",
    "    \n",
    "    for idx in indices[0]:  # Zakładając, że indices[0] zawiera odpowiednie numery indeksów\n",
    "        faiss_titles.append(f\"Article_{idx}\")  # Proszę zmienić w zależności od struktury FAISS\n",
    "    \n",
    "    # Pobierz pełne artykuły z Wikipedii\n",
    "    articles = [get_wikipedia_article(title) for title in faiss_titles]\n",
    "\n",
    "    # Wygenerowanie odpowiedzi z modelu CLARIN\n",
    "    response = generate_response_from_faiss(query, articles)\n",
    "\n",
    "    return response\n",
    "\n",
    "# Testowanie zapytania\n",
    "query = \"What are the applications of AI?\"  # Przykładowe zapytanie\n",
    "response = run_rag_chain(query)\n",
    "\n",
    "print(\"Response from model:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wymiar wektora: 384\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Załaduj plik indeksu FAISS\n",
    "index = faiss.read_index(r\"C:\\Users\\kjani\\nlp\\NLP\\task_3\\index\\wikipedia_202307.index\")\n",
    "\n",
    "# Sprawdź informacje o wymiarze indeksu\n",
    "print(\"Wymiar wektora:\", index.d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Załaduj model do przetwarzania zapytań\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Używamy tego samego modelu, co do tworzenia wektorów\n",
    "\n",
    "# Funkcja przekształcająca tekst w wektor\n",
    "def get_query_embedding(query):\n",
    "    return model.encode([query])\n",
    "\n",
    "# Przykład zapytania\n",
    "query = \"Sztuczna inteligencja\"\n",
    "\n",
    "# Przekształcenie zapytania na wektor\n",
    "query_embedding = np.array(get_query_embedding(query), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podobne artykuły:\n",
      "Indeks 261157 - Odległość: 0.7854613065719604\n",
      "Indeks 5485593 - Odległość: 0.7977433204650879\n",
      "Indeks 5490606 - Odległość: 0.8000825643539429\n",
      "Indeks 5485115 - Odległość: 0.8073369860649109\n",
      "Indeks 261189 - Odległość: 0.8139570355415344\n"
     ]
    }
   ],
   "source": [
    "# Wyszukaj k najbliższych sąsiedztw w indeksie FAISS\n",
    "k = 5  # Liczba wyników\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Wyświetl wyniki\n",
    "print(\"Podobne artykuły:\")\n",
    "for i in range(k):\n",
    "    print(f\"Indeks {indices[0][i]} - Odległość: {distances[0][i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borys Szyc Borys Michał Szyc (ur. 4 września 1978 w Łodzi jako Borys Michał Michalak) – polski aktor teatralny i filmowy, piosenkarz oraz lektor.\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "# Definiujemy niestandardowy User-Agent zgodny z polityką Wikipedii\n",
    "user_agent = \"YourAppName/1.0 (https://example.com; contact@example.com)\"\n",
    "\n",
    "# Tworzymy obiekt Wikipedia z niestandardowym User-Agent\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "    user_agent=user_agent,  # Dodajemy User-Agent jako pierwszy argument\n",
    "    language='pl'           # Ustawiamy język na polski\n",
    ")\n",
    "\n",
    "# Funkcja do pobierania tytułu artykułu na podstawie tytułu\n",
    "def get_article_intro(title):\n",
    "    page = wiki.page(title)\n",
    "    if page.exists():\n",
    "        return title, page.text.split('\\n')[0]  # Zwraca tytuł i pierwsze zdanie\n",
    "    return None\n",
    "\n",
    "# Przykład użycia\n",
    "article_title, first_sentence = get_article_intro(\"Borys Szyc\")\n",
    "print(article_title, first_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import wikipediaapi\n",
    "\n",
    "CLARIN_BASE_URL = \"https://services.clarin-pl.eu/api/v1/oapi\"\n",
    "USER_AGENT = \"YourAppName/1.0 (https://example.com; contact@example.com)\"  # Wikipedia User-Agent\n",
    "\n",
    "# Tworzymy obiekt Wikipedii\n",
    "wiki = wikipediaapi.Wikipedia(user_agent=USER_AGENT, language='pl')\n",
    "\n",
    "\n",
    "# Model Sentence-Transformers (ten sam użyty do generowania indeksu)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Funkcja do wyszukiwania w FAISS\n",
    "def search_faiss(query, k=5):\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    return distances[0], indices[0]\n",
    "\n",
    "# Pobieranie artykułów z Wikipedii\n",
    "def get_article_intro(title):\n",
    "    page = wiki.page(title)\n",
    "    if page.exists():\n",
    "        return title, page.text.split('\\n')[0]  # Zwróć tytuł i pierwsze zdanie\n",
    "    return None\n",
    "\n",
    "# Funkcja do wysyłania zapytania do modelu CLARIN\n",
    "def clarin_chat_completion(model_id, prompt, max_tokens=150):\n",
    "    url = f\"{CLARIN_BASE_URL}/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"model\": model_id,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"CLARIN API Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Przykład: pełny przepływ wyszukiwania i odpowiedzi\n",
    "def handle_query_with_rag(user_query, model_id=\"bielik\", k=5):\n",
    "    # 1. Znajdź artykuły w indeksie FAISS\n",
    "    distances, indices = search_faiss(user_query, k)\n",
    "    \n",
    "    # 2. Pobierz tytuły i wstępy artykułów\n",
    "    articles = []\n",
    "    for idx in indices:\n",
    "        # FAISS indeksuje tytuły; zakładamy, że tytuły odpowiadają numerom indeksu\n",
    "        title = f\"Article_{idx}\"  # Zakładamy istnienie tytułu dla indeksu\n",
    "        intro = get_article_intro(title)\n",
    "        if intro:\n",
    "            articles.append(intro)\n",
    "\n",
    "    # 3. Przygotuj kontekst do zapytania CLARIN\n",
    "    context = \"\\n\\n\".join([f\"{title}: {intro}\" for title, intro in articles])\n",
    "    prompt = f\"Zapytanie: {user_query}\\n\\nKontekst:\\n{context}\\n\\nOdpowiedz w kontekście powyższych informacji.\"\n",
    "\n",
    "    # 4. Wyślij zapytanie do modelu CLARIN\n",
    "    response = clarin_chat_completion(model_id, prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu CLARIN:\n",
      "Edyta Górniak urodziła się dnia 14 listopada 1972 roku w Ziębicach na Dolnym Śląsku, w województwie dolnośląskim.\n",
      "\n",
      "### Kontekst:\n",
      "\n",
      "Jak widać, pytanie dotyczy miejsca urodzenia artystki o imieniu i nazwisku Edyta Górniak. Powyższe informacje potwierdzają, że Edyta Górniak przyszła na świat w mieście Ziębice, znajdującym się na Dolnym Śląsk\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    user_query = \"Gdzie urodziła sie Edyta Górniak?\"\n",
    "    response = handle_query_with_rag(user_query)\n",
    "    print(\"Odpowiedź modelu CLARIN:\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
