{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'id': 'bielik', 'full_name': 'speakleash/Bielik-11B-v2.2-Instruct', 'name': 'speakleash/Bielik-11B-v2.2-Instruct'}, {'id': 'cohere', 'full_name': 'CohereForAI/c4ai-command-r-plus', 'name': 'CohereForAI/c4ai-command-r-plus'}, {'id': 'llama3.1-8b', 'full_name': 'meta-llama/Llama-3.1-8B-Instruct', 'name': 'meta-llama/Llama-3.1-8B-Instruct'}, {'id': 'llama', 'full_name': 'meta-llama/Llama-3.1-8B-Instruct', 'name': 'meta-llama/Llama-3.1-8B-Instruct'}, {'id': 'llama-guard', 'full_name': 'meta-llama/Llama-Guard-3-8B', 'name': 'meta-llama/Llama-Guard-3-8B'}, {'id': 'llama3.1', 'full_name': 'meta-llama/Meta-Llama-3.1-70B-Instruct', 'name': 'meta-llama/Meta-Llama-3.1-70B-Instruct'}, {'id': 'openchat', 'full_name': 'openchat/openchat-3.5-1210', 'name': 'openchat/openchat-3.5-1210'}, {'id': 'mixtral-8x22B', 'full_name': 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'name': 'mistralai/Mixtral-8x22B-Instruct-v0.1'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import CrossEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from typing import Literal\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"CLARIN_API_KEY\")\n",
    "\n",
    "MODELS_ENDPOINT = \"https://services.clarin-pl.eu/api/v1/oapi/models\"\n",
    "COMPLETIONS_ENDPOINT = \"https://services.clarin-pl.eu/api/v1/oapi/chat/completions\"\n",
    "\n",
    "def get_models():\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',  \n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.get(MODELS_ENDPOINT, headers=headers)  \n",
    "    if response.status_code == 200:\n",
    "        return response.json()  \n",
    "\n",
    "models = get_models()\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reranker():\n",
    "    \n",
    "    def __init__(self, model_name: str, max_length: int = 512) -> None:\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.model_rank = CrossEncoder(self.model_name, \n",
    "                                       max_length = self.max_length, \n",
    "                                       device = self.device)\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name, \n",
    "                                                       max_length = self.max_length)\n",
    "    \n",
    "    \n",
    "    def rank_answers(self, query: str, answers: list[str], top_k: int = 5) -> list[dict[Literal['corpus_id', 'score', 'text'], int | float | str]]:\n",
    "        self.query = query\n",
    "        self.top_k = top_k\n",
    "        self.answers_ranking = self.model_rank.rank(query, \n",
    "                                                    answers,\n",
    "                                                    top_k = 300,\n",
    "                                                    return_documents = True,\n",
    "                                                    show_progress_bar = True)\n",
    "        \n",
    "        print(f'Zapytanie: {self.query}')\n",
    "        for k in range(self.top_k):\n",
    "            print(f'Odpowiedź {k + 1}: {self.answers_ranking[k][\"text\"]}')\n",
    "    \n",
    "    \n",
    "    def find_embeddings(self) -> list[dict[torch.Tensor, str]]:\n",
    "        question = self.query\n",
    "        answers = [dct['text'] for dct in self.answers_ranking]\n",
    "        texts = [question, *answers]\n",
    "        labels = ['Zapytanie', *[f'Top {self.top_k} odpowiedzi'] * self.top_k, *['Pozostałe odpowiedzi'] * (len(answers) - self.top_k)]\n",
    "        tensors = []\n",
    "        \n",
    "        for text in texts:\n",
    "            inputs = self.tokenizer(text, \n",
    "                                return_tensors = 'pt', \n",
    "                                truncation = True, \n",
    "                                padding = True, \n",
    "                                max_length = self.max_length).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model_rank.model.bert(**inputs)\n",
    "                \n",
    "            embedding = outputs.last_hidden_state[:, 0, :].squeeze()   # EMBEDDING TOKENU [CLS]\n",
    "            # embedding = outputs.last_hidden_state.mean(dim = 1).squeeze()   # ŚREDNIA Z EMBEDDINGÓW DLA WSZYSTKICH TOKENÓW\n",
    "            tensors.append(embedding)\n",
    "        \n",
    "        emb_tensor = torch.stack(tensors)\n",
    "        \n",
    "        self.emb_tensor = emb_tensor\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    \n",
    "    \n",
    "    def plot_embeddings(self) -> None:\n",
    "            \n",
    "        embs, texts, labels  = self.emb_tensor, self.texts, self.labels\n",
    "        pca = TSNE(n_components = 2, perplexity = 10)\n",
    "        pca_embs = pca.fit_transform(embs.cpu().numpy())\n",
    "        \n",
    "        df = pd.DataFrame({'x': pca_embs[:, 0], 'y': pca_embs[:, 1], 'texts': texts, 'label': labels})\n",
    "        df['texts'] = df['texts'].apply(lambda text: text[:100] + '...' if len(text) > 100 else text)\n",
    "        \n",
    "        \n",
    "        fig = px.scatter(df, x = 'x', y = 'y', color = 'label',\n",
    "            title = 'Wizualizacja osadzeń dla modelu re-ranker',\n",
    "            labels = {'label': 'Legenda'},\n",
    "            hover_name = df['texts']\n",
    "        )\n",
    "        fig.update_traces(marker = dict(size = 10), selector = dict(mode = 'markers'))\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 211387.70 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 217359.74 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 204082.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(dataset, model):\n",
    "    reviews = dataset[\"train\"][\"text\"] \n",
    "    embeddings = model.encode(reviews, convert_to_numpy=True).astype(\"float32\")\n",
    "\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])  \n",
    "    index.add(embeddings)  \n",
    "    return index, reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faiss(query, k=5):\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    result_reviews = [reviews[idx] for idx in indices[0]]\n",
    "    return distances[0], result_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clarin_chat_completion(model_id, prompt, max_tokens=200):\n",
    "    url = f\"{CLARIN_BASE_URL}/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"model\": model_id,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"CLARIN API Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query_with_rag(user_query, model_id=\"bielik\", k=5):\n",
    "    distances, result_reviews = search_faiss(user_query, k)\n",
    "\n",
    "    context = \"\\n\\n\".join([f\"Recenzja {i+1}: {review}\" for i, review in enumerate(result_reviews)])\n",
    "    if not context.strip():\n",
    "        context = \"Brak dodatkowego kontekstu.\"\n",
    "\n",
    "    prompt = f\"Zapytanie: {user_query}\\n\\nKontekst:\\n{context}\\n\\nOdpowiedz w kontekście powyższych informacji.\"\n",
    "    response = clarin_chat_completion(model_id, prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "index, reviews = build_faiss_index(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, 'index/imdb_faiss.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź: Wybór najlepszego filmu do oglądania z przyjaciółmi zależy od kilku czynników, takich jak gust grupy, okazja oraz tematyka filmu. Ze swojej perspektywy mogę polecić kilka tytułów, które nadają się znakomicie na seans w towarzystwie znajomych.\n",
      "\n",
      "Jeśli szukasz lekkiego i pełnego humoru filmu, świetną opcją będą komedie romantyczne, takie jak \"Notting Hill\" czy \"Dziewczyna z sąsiedztwa\". Oba te filmy nie tylko zapewnią sporo śmiechu, ale także stworzą miłą atmosferę do rozmowy po projekcji.\n",
      "\n",
      "Dla fanów animacji polecam \"Toy Story\", serię filmów o Toy Story jest niezwykle uroczym i uniwersalnym wyborem, który spodoba się widzom w każdym wieku. Filmy te mają znakomitą fabułę oraz piękne przesłanie, a ich różnorodność sprawi, że nikt się nie znudzi.\n",
      "\n",
      "Miłośnicy kina akcji mogą cieszyć się przygodami w cyklu \"Mad Max\" - te niezwykle dynamiczne i pełne spektakularnych efektów specjalnych produkcje zapewnią mocne wrażenia i dodadzą energii do spotkania ze znajomymi.\n",
      "\n",
      "A jeśli chcesz wprowadzić intelektualny wymiar do waszej sesji filmowej, spróbujcie poruszyć ważkie kwestie w filmach takich jak \"Siedem dusz\" czy \"Prestige\". Obydwa te filmy oferują głębię psychologiczną i moralne dylematy, co może stanowić doskonały punkt wyjścia do interesujących d\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What is the best movie to watch with friends?\"\n",
    "response = handle_query_with_rag(user_query)\n",
    "print(\"Odpowiedź:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W oparciu o podane informacje, nie możemy bezpośrednio określić dokładnej opinii ludzi o horrorach, ponieważ zamiast treści recenzji mamy tylko numery referencyjne. Jednakże na ich podstawie możemy sformułować następujące domysły:\\n\\n1. Skoro są to recenzje filmów grozy, prawdopodobnie ludzie mają różnorodne opinie - od negatywnych po entuzjastyczne. \\n\\n2. Numery recenzji sugerują, że opinie byłyby rozłożone na kilka tysięcy widzów (np. dla recenzji 23708 - prawie 24 tysiące). W tak dużej grupie spodziewalibyśmy się również pogłębionej różnorodności preferencji i emocji wobec horrorów.\\n\\n3. Możliwe, że niektóre z tych recenzji dotyczą klasyków gatunku jak \"Psychoza\" czy \"Piła\", inne mogłyby omawiać najnowsze produkcje lub niszowe kino grozy.\\n\\nAby uzyskać szczegółową opinię publiczną na temat horrorów, potrzebne byłyby pełne treści tych recenzji oraz dodatkowe dane ze sprzedaży biletów, liczby wyświetleń czy reakcji w mediach społecznościowych. Jednocześnie pamiętajmy, że opinie osobiste ulegają zmianom i są konstruowane z różnych doświadczeń, uprzedzeń oraz osobistych doświadczeń widzów.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_query_with_rag(\"What do people think about horror movies?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeks został zapisany na dysk.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import faiss\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"CLARIN_API_KEY\")\n",
    "\n",
    "\n",
    "CLARIN_BASE_URL = \"https://services.clarin-pl.eu/api/v1/oapi\"\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    headers = {'Authorization': f'Bearer {API_KEY}', 'Content-Type': 'application/json'}\n",
    "    response = requests.get(f\"{CLARIN_BASE_URL}/models\", headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch models: {response.status_code} - {response.text}\")\n",
    "\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "\n",
    "def build_faiss_index(dataset, model):\n",
    "    reviews = dataset[\"train\"][\"text\"]\n",
    "    embeddings = model.encode(reviews, convert_to_numpy=True).astype(\"float32\")\n",
    "    \n",
    "    d = embeddings.shape[1]  \n",
    "    quantizer = faiss.IndexFlatL2(d)  \n",
    "\n",
    "    nlist = 100 \n",
    "    m = 8  \n",
    "    nbits = 8  \n",
    "    index = faiss.IndexIVFPQ(quantizer, d, nlist, m, nbits)  \n",
    "\n",
    "    index.train(embeddings)  \n",
    "    index.add(embeddings)  \n",
    "\n",
    "    faiss.write_index(index, \"index/imdb_faiss_ivfpq.bin\")\n",
    "    print(\"Indeks został zapisany na dysk.\")\n",
    "\n",
    "    return index, reviews\n",
    "\n",
    "\n",
    "def search_faiss(index, query, model, reviews, k=5):\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    result_reviews = [reviews[idx] for idx in indices[0]]\n",
    "    return distances[0], result_reviews\n",
    "\n",
    "def rerank_with_cross_encoder(query, result_reviews, reranker, k=5):\n",
    "\n",
    "    pairs = [[query, review] for review in result_reviews]\n",
    "\n",
    "    rerank_scores = reranker.predict(pairs)\n",
    "\n",
    "    ranked_reviews = [result_reviews[i] for i in sorted(range(len(rerank_scores)), key=lambda i: rerank_scores[i], reverse=True)]\n",
    "    return ranked_reviews[:k]\n",
    "\n",
    "def clarin_chat_completion(model_id, prompt, max_tokens=300):\n",
    "    url = f\"{CLARIN_BASE_URL}/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"model\": model_id,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"CLARIN API Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "index, reviews = build_faiss_index(dataset, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query_with_rag(user_query,reranker, model_id=\"mixtral-8x22B\", k=8):\n",
    "    distances, result_reviews = search_faiss(index, user_query, model, reviews, 50)\n",
    "\n",
    "    reranked_reviews = rerank_with_cross_encoder(user_query, result_reviews, reranker, k)\n",
    "\n",
    "    context = \"\\n\\n\".join([f\"Recenzja {i+1}: {review}\" for i, review in enumerate(reranked_reviews)])\n",
    "    if not context.strip():\n",
    "        context = \"Brak dodatkowego kontekstu.\"\n",
    "\n",
    "    prompt = f\"Zapytanie: {user_query}\\n\\nKontekst:\\n{context}\\n\\nOdpowiedz zwięźle w kontekście powyższych informacji.\"\n",
    "    response = clarin_chat_completion(model_id, prompt)\n",
    "    return response, context\n",
    "\n",
    "def evaluate_response_with_llama(question, context, answer, model_id=\"bielik\"):\n",
    "\n",
    "    prompt = f\"Na podstawie poniższego kontekstu i pytania, oceń, jak trafna i spójna jest odpowiedź modelu '{answer}' w odniesieniu do pytania '{question}':\\n\\nKontekst: {context}\\n\\nCzy odpowiedź jest trafna i zgodna z kontekstem? Oceń odpowiedź na skali od 1 do 10, gdzie 1 to 'bardzo nietrafna', a 10 to 'bardzo trafna'. Dodaj krótki komentarz co poprawić.\"\n",
    "\n",
    "    evaluation = clarin_chat_completion(model_id, prompt)\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Użyty kontekst:\n",
      " Recenzja 1: This is hands down the worst movie of all time. A combination of Whoopie Goldberg (the worst actress/person in history) and a talking dinosaur ala Jar-Jar-Binks add up to a painfully bad movie. That was an understatement. This movie is unwatchable. For the love of God, do not watch this movie.\n",
      "\n",
      "Recenzja 2: The thing about calling \"House of the Dead\" the worst movie of all time is that it's really not. There are worse movies out there. I watch alot of Hong Kong ninja movies that are basically the result of an unfinished Japanese police drama having footage of ninjas inserted at the end to create something that could technically be called \"a movie.\"<br /><br />House of the Dead is however one of the worst films I've ever seen at the theatres. Walking out half way through, I actually felt I was somewhat dumber for having set through 45 minutes of this piece of garbage.\n",
      "\n",
      "Recenzja 3: This is surely one of the worst films ever made. Each scene is painful. You will groan at the flimsy attempts at humor, the awkward camera work, the sexism and racism, the ridiculous story line, the wooden acting. Poor Joan Bennett; she is the only one in the movie who is not an embarrassment. In all, dreadful.\n",
      "\n",
      "Recenzja 4: Worst movie, (with the best reviews given it) I've ever seen. Over the top dialog, acting, and direction. more slasher flick than thriller.With all the great reviews this movie got I'm appalled that it turned out so silly. shame on you martin scorsese\n",
      "\n",
      "Recenzja 5: I've seen about 820 movies released between 1931-39, and THE INFORMER is the worst major release I've seen from that time span. Awful, despicable, unpleasant, unhappy, unredeemable saga of a complete Loser. Watch a 1934 B Western instead.\n",
      "\n",
      "Recenzja 6: Recipe for one of the worst movies of all time: a she-male villain who looks like it escaped from the WWF, has terrible aim with a gun that has inconsistent effects (the first guy she shoots catches on fire but when she shoots anyone else they just disappear) and takes time out to pet a deer. Then you got the unlikable characters, 30 year old college students, a lame attempt at a surprise ending and lots, lots more. Avoid at all costs.\n",
      "\n",
      "Recenzja 7: The worst movie in the history of cinema. I don't know if it was trying to be funny or sad, poignant or droll, but the end result was unwatchable. Everyone from Key Grip, to Robin Williams, and back down to Best Boy should be ashamed to be a part of this film!\n",
      "\n",
      "Recenzja 8: I caught this movie on FX last night, and as I was sitting there watching it, it occurred to me that it could quite possibly be the worst movie ever. Bad acting, bad cinematography, bad sound, totally unbelievable fight sequences, stupid characters. All these made it up to be the most laughably bad movie I've ever seen. It was so bad, I was enthralled by it's sheer lack of anything semi-competent that I had to keep watching... and they made a sequel!\n",
      "Odpowiedź:  Based on the given reviews, here are some of the movies considered as the worst:\n",
      "1. The Star of Jaipur - criticized for poor humor, awkward camera work, sexism, racism, and a ridiculous storyline.\n",
      "2. House of the Dead - described as one of the worst films seen in theatres, with poor quality and a lack of intelligence.\n",
      "3. An unnamed movie with a she-male villain - criticized for its unlikable characters, unrealistic effects, and a lame attempt at a surprise ending.\n",
      "4. The Informer (1935) - considered the worst major release from 1931-39, with an awful, despicable, and unredeemable saga of a loser.\n",
      "5. Another unnamed movie - criticized for bad acting, cinematography, sound, unbelievable fight sequences, and stupid characters.\n",
      "\n",
      "The above reviews are subjective and based on individual opinions, but they provide insight into some of the movies that have been poorly received.\n",
      "Ocena: Ocena: 8/10\n",
      "\n",
      "Komentarz: Trafność: Odpowiedź jest bardzo pomocna i zawiera kilka powtarzających się tytułów, które zostały wielokrotnie skrytykowane przez recenzentów, takich jak \"The Informer\" oraz brak tytułów przy wspomnianych punktach 2, 4 i 5. Spójność: Jest spójna z podanymi recenzjami, ponieważ opisuje filmy, które wywołują negatywne opinie dotyczące aktorstwa, reżyserii, fabuły itp.\n",
      "\n",
      "Poprawa:\n",
      "Dla lepszej przejrzystości i rozpoznawalności, warto byłoby:\n",
      "1) Uzupełnić/sprecyzować tytuły wspomnianych filmów.\n",
      "2) Podsumować główne krytykowane aspekty każdego filmu z osobna.\n",
      "3) Uporządkować listę chronologicznie lub według częstotliwości występowania w recenzjach.\n"
     ]
    }
   ],
   "source": [
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "user_query = \"What are the worst movies?\"\n",
    "\n",
    "response, context = handle_query_with_rag(user_query, reranker)\n",
    "\n",
    "print(\"Użyty kontekst:\\n\", context)\n",
    "\n",
    "evaluation = evaluate_response_with_llama(user_query, context, response)\n",
    "\n",
    "print(\"Odpowiedź:\", response)\n",
    "print(\"Ocena:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
